<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jun Li</title>
  <meta name="author" content="Jun Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: Arial, sans-serif;
      font-size: 30px;
    }
  </style>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/doraemeng.JPG">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <!-- <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JunLi.JPG", target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JunLi.JPG" class="hoverZoomLink"></a>
            </td> -->
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JunLi.JPG" target="_blank">
                <img style="width:100%;max-width:100%; border-radius: 50%;" alt="profile photo" src="images/JunLi.JPG" class="hoverZoomLink">
              </a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left; display: flex; align-items: center;" >
                <name>Jun Li</name>
              </p>
            <p style="line-height: 1.8em;">‚ÄãPh.D. Student
              <br>
              Technical University of Munich, Munich Center for Machine Learning
              <br>
              <em>Hobbies: </em>üõπüéπüö¥‚Äç‚ôÄÔ∏èüéßüèãÔ∏èüë©‚Äçüíª
              <br>
              <em>üåü Keep your eyes on the stars, and your feet on the ground.ü§ûüèª</em>
              <br>
            </p>
            
            <p style="text-align:left;">
                <span class="icon" style="margin: 0.8%;"><a href="https://scholar.google.com/citations?user=t9vB5TgAAAAJ&hl=en" target="_blank"><img src="images/icons/scholar_bbg.png" alt="Google Scholar"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="https://github.com/LijunRio" target="_blank"><img src="images/icons/github_2.png" alt="GitHub"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="mailto:june.li@tum.de"><img src="images/icons/email_icon.png" alt="Email"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="https://www.linkedin.com/in/jun-li-657295290/" target="_blank"><img src="images/icons/linkedin.png" alt="LinkedIn"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="pdf/CV.pdf" target="_blank"><img src="images/icons/cv_icon.png" alt="CV"></a></span>
            </p>
          

          </tr>
        </tbody></table>
        <br><hr>
        <heading>üì£News</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;width:100%;vertical-align:middle">
              <p>
              <p style="line-height: 1.8em;"></p>
                <strong>[04.2025]</strong>&nbsp;
                <em>My new seminar üìö <strong>AI for Vision-Language Models in Medical Imaging (IN2107, IN45069)</strong> is now open! For more details, please visit <a href="https://github.com/LijunRio/Master-Seminar-AI-for-Vision-Language-Models-in-Medical-Imaging-IN2107-IN45069-" target="_blank">the course GitHub repository</a>.</em>
                <br>
                
              </p>
              <p style="line-height: 1.8em;">
              <strong>[06.2024]</strong> &nbsp;
              <em>My seminar üìò <strong>AI for Vision-Language Pre-training in Medical Imaging (IN2107)</strong> is now open! For more details, please visit <a href="https://github.com/LijunRio/VLP-Seminar" target="_blank">the course GitHub repository</a>.</em>
              <br>
                
              </p>
              </p>
            </td>
          </tr>
        </tbody></table>

        <br><hr>
        <heading>üòéShort Bio</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;width:100%;vertical-align:middle">
              <p>
                ‚ÄãI am currently a Ph.D. student in the¬†<a href="https://www.cit.tum.de/cit/startseite/", target="_blank">School of Computation, Information and Technology</a>,¬†<a href="https://www.tum.de/", target="_blank"> Technical University of Munich</a>, supervised by¬†<a href="https://www.professoren.tum.de/schnabel-julia", target="_blank">Prof. Julia Schnabel</a>. I am funded by the <a href="https://mcml.ai/", target="_blank"> Munich Center for Machine Learning (MCML)</a>.
                Previously, I received the M. Eng. degree from <a href="https://english.ucas.ac.cn/", target="_blank">University of the Chinese Academy of Sciences </a>, under the supervison from <a href="https://ieeexplore.ieee.org/author/37403242300", target="_blank">Prof. Ying Hu</a>.
              </p>
              <p>
                My research focused on the intersection of deep learning and healthcare, particularly in the analysis of medical images. My passion lies in improving the practicality of deep learning algorithms, with a primary focus on Vision and Language models, Cross-Modality Generation, and Multi-Modality Learning. Through my work in these areas, I aim to advance deep learning techniques and their transformative impact on healthcare.
              </p>
            </td>
          </tr>
        </tbody></table>

        <br><hr>
        <heading>üìöPublications</heading>
        <table class="paper-container"><tbody>
           <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/K2-Sight.jpg" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Knowledge to Sight: Reasoning over Visual Attributes via Knowledge Decomposition for Abnormality Grounding</papertitle>
              <br>
              <strong>Jun Li</strong>, Che Liu, Wenjia Bai, Mingxuan Liu, Rossella Arcucci, Cosmin I. Bercea, Julia A. Schnabel
              <br>
              [<a href="https://arxiv.org/pdf/2508.04572",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/K2Sight/" target="_blank">homepage</a>]
            </p>
            </td>
          </tr>
          <br>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/NOVA.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI</papertitle>
              <br>
              Cosmin I. Bercea, <strong>Jun Li</strong>, Philipp Raffler, Evamaria O. Riedel, Lena Schmitzer, Angela Kurz, Felix Bitzer, Paula Ro√üm√ºller, Julian Canisius, Mirjam L. Beyrle, Che Liu, Wenjia Bai, Bernhard Kainz, Julia A. Schnabel, Benedikt Wiestler.
              <br>
              [<a href="https://arxiv.org/abs/2505.14064",  target="_blank">paper</a>]
              [<a href="https://huggingface.co/papers/2505.14064" target="_blank">huggingface</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/AG-KD.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Enhancing Abnormality Grounding for Vision-Language Models with Knowledge Descriptions</papertitle>
              <br>
              <strong>Jun Li</strong>, Che Liu, Wenjia Bai, Rossella Arcucci, Cosmin I. Bercea, Julia A. Schnabel.
              <br>
              [<a href="https://arxiv.org/abs/2503.03278",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/AG-KD/" target="_blank">project</a>]
              [<a href="https://huggingface.co/spaces/RioJune/AG-KD" target="_blank">huggingface</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/OUI.jpg" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Organizing Unstructured Image Collections using Natural Language</papertitle>
              <br>
              Mingxuan Liu, Zhun Zhong, <strong>Jun Li</strong>, Gianni Franchi, Subhankar Roy, Elisa Ricci.
              <br>
              [<a href="https://arxiv.org/abs/2410.05217",  target="_blank">paper</a>]
            </p>
            </td>
          </tr>
          
           <!-- Paper item -->
           <tr>
            <td class="paper-item-img">
              <img src="images/papers/ffmbench.jpg" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Fmbench: Benchmarking fairness in multimodal large language models on medical tasks</papertitle>
              <br>
              Peiran Wu, Che Liu, Canyu Chen, <strong>Jun Li</strong>, Cosmin I Bercea, Rossella Arcucci.
              <br>
              [<a href="https://arxiv.org/abs/2410.01089",  target="_blank">paper</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/MI-VQA.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Language Models Meet Anomaly Detection for Better Interpretability and Generalizability</papertitle>
              <br>
              <em>Accepted by MMMI 2024.</em>
              <br>
              <strong>Jun Li</strong>, Su Hwan Kim, Philip Mller, Lina Felsner, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea.
              <br>
              [<a href="https://arxiv.org/pdf/2404.07622.pdf",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/Multi-Image-VQA-for-UAD/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/DSD.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Design as Desired: Utilizing Visual Question Answering for Multimodal Pre-training</papertitle>
              <br>
              <em>Accepted by MICCAI 2024.</em>
              <br>
              Tongkun Su*, <strong>Jun Li*</strong>, Xi Zhang, Haibo Jin, Hao Chen, Qiong Wang, Faqin Lv, Baoliang Zhao, Yin Hu
              <br>
              [<a href="https://arxiv.org/pdf/2404.00226.pdf",  target="_blank">paper</a>]
              [<a href="https://github.com/MoramiSu/QFT-MICCAI2024" target="_blank">Code</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/URG.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Ultrasound Report Generation with Cross-Modality Feature Alignment via Unsupervised Guidance</papertitle>
              <br>
              <em>IEEE Transactions on Medical Imaging (IF:10.6).</em>
              <br>
              <strong>Jun Li</strong>, Tongkun Su, Baoliang Zhao, Faqin Lv, Qiong Wang, Nassir Navab, Ying Hu, Zhongliang Jiang.
              <br>
              [<a href="https://arxiv.org/abs/2406.00644",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/Ultrasound-Report-Generation/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
           <!-- Paper item -->
           <tr>
            <td class="paper-item-img">
              <img src="images/papers/MICCAI22_SGF.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>A Self-guided Framework for Radiology Report Generation</papertitle>
              <br>
              <em>Accepted by MICCAI 2022.</em>
              <em>(<span style="font-style: italic; color: red;">Early Accept</span>)</em>
              <br>
              <em>(Student Travel Award, Top 5%)</em>
              <br>
              <strong>Jun Li</strong>, Shibo Li, Ying Hu, Huiren Tao.
              <br>
              [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16452-1_56",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/A-Self-Guided-Framework/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/CMIG_2022.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>XctNet: Reconstruction network of volumetric images from a single X-ray image</papertitle>
              <br>
              <em>Computerized Medical Imaging and Graphics (<b>CMIG</b>), 2022.</em>
              <br>
              Zhiqiang Tan, <strong>Jun Li</strong>, Huiren Tao, Shibo Li, Ying Hu .              
              <br>
              [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611122000404",  target="_blank">paper</a>] 
            </p>
            </td>
          </tr>
        </tbody></table>  
        <br><hr>
        <heading>üìåOthers</heading>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <ul style="height: auto;">
                <li>Teaching:</li>
                <ul style="height: auto;">
                  <li><a href="https://github.com/LijunRio/Master-Seminar-AI-for-Vision-Language-Models-in-Medical-Imaging-IN2107-IN45069-" target="_blank">(S 25) AI for Vision-Language Models in Medical Imaging (IN2107, IN45069)</a>.</li> 
                  <li><a href="https://github.com/LijunRio/VLP-Seminar" target="_blank">(S 24/25) AI for Vision-Language Pre-training in Medical Imaging (IN2107)</a>.</li> 
                </ul>
              </ul>
              <ul style="height: auto;">
                <li>Conference Reviewer:</li>
                <ul style="height: auto;">
                  <li>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2025.</li> 
                  <li>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2024.</li> 
                </ul>
              <li>Activities:</li>
              <ul style="height: auto;">
                <li><a href="https://iplab.dmi.unict.it/icvss2024/" target="_blank">International Summer School in Computer Vision (ICVSS)</a>, Sicily, 2024.</li>
              </ul>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <br><hr>
        <heading>üßë‚Äçüíª Internships</heading>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <ul style="height: auto;">
                <li><b>AI Algorithm Engineer</b>, at Xiaohongshu App, Beijing, China, 2021.</li>
                <li><b>STEAM education Engineer</b>, at DJI Technology, Shenzhen, China, 2020.</li>
                <li><b>Content Management</b>, at Tencent Music Entertainment, Shenzhen, China, 2019.</li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <br><hr>
        <heading>üèÜAwards</heading>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <ul style="height: auto;">
                <li><b>National Scholarship</b>, from the ministry of Education of China, 2022.
                </li>
                <li>Outstanding Student, from University of Chinese Academy of Sciences, 2021-2022.
                </li>
                <li>Outstanding Student Leader, from University of Chinese Academy of Sciences, 2021-2022.
                </li>
                <li><b>National 1th Prize</b> in RoboMaster University Technical Challenge, 2019.
                </li>
                <li><b>National 1th Prize</b> in RoboMaster University Championship, 2019.
                </li>
                <li><b>National Special Prize</b> in RoboMaster University Technical Challenge, 2018.
                </li>
                <li><b>National 2th Prize</b> in RoboMaster University Championship, 2018.
                </li>
                <li><b>Pengcheng scholarship</b> of Shenzhen University (Top 1%), 2019.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <br><hr>
        <br>
        <br>
        <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=LpkeCEOsLWcfMT_2Q--JRRvMAuxzTlQA23wCR6roJiY&cl=ffffff&w=300"></script> -->
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=340&t=tt&d=LpkeCEOsLWcfMT_2Q--JRRvMAuxzTlQA23wCR6roJiY&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff&w=400'></script>
        <footer>
          <p style="text-align:center"> ¬© Jun Li | Homepage</p>
          <p style="text-align:center;font-size:small;">
            Design and source code from <a style="font-size:small;" href="https://jonbarron.info", target="_blank">Jon Barron's website</a>.
          </a></p>
        </footer>


      </td>
    </tr>
  </table>
</body>

</html>
