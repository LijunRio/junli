<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jun Li</title>
  
  <meta name="author" content="Jun Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/doraemeng.JPG">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <!-- <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JunLi.JPG", target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JunLi.JPG" class="hoverZoomLink"></a>
            </td> -->
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JunLi.JPG" target="_blank">
                <img style="width:100%;max-width:100%; border-radius: 50%;" alt="profile photo" src="images/JunLi.JPG" class="hoverZoomLink">
              </a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left; display: flex; align-items: center;" >
                <name>Jun Li</name>
              </p>
            <p style="line-height: 1.8em;">‚ÄãPh.D. Student
              <br>
              Technical University of Munich, Munich Center for Machine Learning
              <br>
              <em>üåü Keep your eyes on the stars, and your feet on the ground.ü§ûüèª</em>
              <br>
            </p>
            
            <p style="text-align:left;">
                <span class="icon" style="margin: 0.8%;"><a href="https://scholar.google.com/citations?user=t9vB5TgAAAAJ&hl=en" target="_blank"><img src="images/icons/scholar_bbg.png" alt="Google Scholar"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="https://github.com/LijunRio" target="_blank"><img src="images/icons/github_2.png" alt="GitHub"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="mailto:june.li@tum.de"><img src="images/icons/email_icon.png" alt="Email"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="https://www.linkedin.com/in/jun-li-657295290/" target="_blank"><img src="images/icons/linkedin.png" alt="LinkedIn"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="pdf/CV.pdf" target="_blank"><img src="images/icons/cv_icon.png" alt="CV"></a></span>
            </p>
          

          </tr>
        </tbody></table>
        <br><hr>
        <heading>Short Bio</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;width:100%;vertical-align:middle">
              <p>
                ‚ÄãI am currently a first year Ph.D. student in the¬†<a href="https://www.cit.tum.de/cit/startseite/", target="_blank">School of Computation, Information and Technology</a>,¬†<a href="https://www.tum.de/", target="_blank"> Technical University of Munich</a>, supervised by¬†<a href="https://www.professoren.tum.de/schnabel-julia", target="_blank">Prof. Julia Schnabel</a>. I am funded by the <a href="https://mcml.ai/", target="_blank"> Munich Center for Machine Learning (MCML)</a>.
                Previously, I received the M. Eng. degree from <a href="https://english.ucas.ac.cn/", target="_blank">University of the Chinese Academy of Sciences </a>, under the supervison from <a href="https://ieeexplore.ieee.org/author/37403242300", target="_blank">Prof. Ying Hu</a>.
              </p>
              <p>
                I am a dedicated researcher focused on the intersection of deep learning and healthcare, particularly in the analysis of medical images. My passion lies in improving the practicality of deep learning algorithms, with a primary focus on Vision and Language models, Cross-Modality Generation, and Multi-Modality Learning. Through my work in these areas, I aim to advance deep learning techniques and their transformative impact on healthcare.
              </p>
            </td>
          </tr>
        </tbody></table>

        <br><hr>
        <heading>Publications</heading>
        <table class="paper-container"><tbody>
          <br><br>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/MI-VQA.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Language Models Meet Anomaly Detection for Better Interpretability and Generalizability</papertitle>
              <br>
              <em>Accepted by MMMI 2024.</em>
              <br>
              <strong>Jun Li</strong>, Su Hwan Kim, Philip Mller, Lina Felsner, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea.
              <br>
              [<a href="https://arxiv.org/pdf/2404.07622.pdf",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/Multi-Image-VQA-for-UAD/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/DSD.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Design as Desired: Utilizing Visual Question Answering for Multimodal Pre-training</papertitle>
              <br>
              <em>Accepted by MICCAI 2024.</em>
              <br>
              Tongkun Su*, <strong>Jun Li*</strong>, Xi Zhang, Haibo Jin, Hao Chen, Qiong Wang, Faqin Lv, Baoliang Zhao, Yin Hu
              <br>
              [<a href="https://arxiv.org/pdf/2404.00226.pdf",  target="_blank">paper</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/URG.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Ultrasound Report Generation with Cross-Modality Feature Alignment via Unsupervised Guidance</papertitle>
              <br>
              <em>IEEE Transactions on Medical Imaging (IF:10.6).</em>
              <br>
              <strong>Jun Li</strong>, Tongkun Su, Baoliang Zhao, Faqin Lv, Qiong Wang, Nassir Navab, Ying Hu, Zhongliang Jiang.
              <br>
              [<a href="https://arxiv.org/abs/2406.00644",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/Ultrasound-Report-Generation/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
           <!-- Paper item -->
           <tr>
            <td class="paper-item-img">
              <img src="images/papers/MICCAI22_SGF.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>A Self-guided Framework for Radiology Report Generation</papertitle>
              <br>
              <em>Accepted by MICCAI 2022.</em>
              <em>(<span style="font-style: italic; color: red;">Early Accept</span>)</em>
              <br>
              <em>(Student Travel Award, Top 5%)</em>
              <br>
              <strong>Jun Li</strong>, Shibo Li, Ying Hu, Huiren Tao.
              <br>
              [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16452-1_56",  target="_blank">paper</a>]
              [<a href="https://lijunrio.github.io/A-Self-Guided-Framework/" target="_blank">project</a>]
            </p>
            </td>
          </tr>
          <!-- Paper item -->
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/CMIG_2022.png" alt="clean-usnob" width="250" height="120">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>XctNet: Reconstruction network of volumetric images from a single X-ray image</papertitle>
              <br>
              <em>Computerized Medical Imaging and Graphics (<b>CMIG</b>), 2022.</em>
              <br>
              Zhiqiang Tan, <strong>Jun Li</strong>, Huiren Tao, Shibo Li, Ying Hu .              
              <br>
              [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611122000404",  target="_blank">paper</a>] 
            </p>
            </td>
          </tr>
        </tbody></table>  
        <br><hr>
        <heading>Awards</heading>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <ul style="height: auto;">
                <li><b>National Scholarship</b>, from the ministry of Education of China, 2022.
                </li>
                <li>Outstanding Student, from University of Chinese Academy of Sciences, 2021-2022.
                </li>
                <li>Outstanding Student Leader, from University of Chinese Academy of Sciences, 2021-2022.
                </li>
                <li><b>National 1th Prize</b> in RoboMaster University Technical Challenge, 2019.
                </li>
                <li><b>National 1th Prize</b> in RoboMaster University Championship, 2019.
                </li>
                <li><b>National Special Prize</b> in RoboMaster University Technical Challenge, 2018.
                </li>
                <li><b>National 2th Prize</b> in RoboMaster University Championship, 2018.
                </li>
                <li><b>Pengcheng scholarship</b> of Shenzhen University (Top 1%), 2019.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <br><hr>
        <heading>Service</heading>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <ul style="height: auto;">
                <li>Conference Reviewer:</li>
                <ul style="height: auto;">
                  <li>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2024.</li> <!-- Â≠êÈ°π -->
                </ul>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <br><hr>
        <br>
        <br>
        <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=LpkeCEOsLWcfMT_2Q--JRRvMAuxzTlQA23wCR6roJiY&cl=ffffff&w=300"></script> -->
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=340&t=tt&d=LpkeCEOsLWcfMT_2Q--JRRvMAuxzTlQA23wCR6roJiY&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff&w=400'></script>
        <footer>
          <p style="text-align:center"> ¬© Jun Li | Homepage</p>
          <p style="text-align:center;font-size:small;">
            Design and source code from <a style="font-size:small;" href="https://jonbarron.info", target="_blank">Jon Barron's website</a>.
          </a></p>
        </footer>


      </td>
    </tr>
  </table>
</body>

</html>
